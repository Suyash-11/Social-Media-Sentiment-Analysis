---
title: "Social Media Minning"

author: "Suyash Tiwari"
date:"12/21/2017"
output: html_document:
toc: yes
---


```{r}
#install.packages("twitteR")
library("twitteR")
#install.packages(c('ROAuth','RCurl'))
require('ROAuth')
require('RCurl')
```

```{r}
# all this info is obtained for the Twitter developer account
key = "WDJyhx2XWRjO2xtH5WTRW7K0l"

secret = "TtEl8Ug5qZuipPrBL6SGZgXEmcIDX6wtDQrAMADaK0hanAJWsj"
mytoken = "119706736-QwM3Isu7tHIC7qncviteQ2AAit6e4lxwU9PwBoGD"
secrettk = "7TLtNs7K6nQTAseaBpO9hvLr8NbBxXn10j1oCFoBENRHP"
# set a working directory for the whole process - you need to download a few files 
# and R needs to know where to look for that stuff
setwd("C:/Users/suyas/Downloads/TwitteR")

# this is crucial step - at least for windows users
# if you are on Linux or Mac you might skip this step, Win needs the certificate collection
# Cacert.pem is a collection of certificates
download.file(url="http://curl.haxx.se/ca/cacert.pem", 
              destfile="C:/Users/suyas/Downloads/TwitteR/cacert.pem",
              method="auto")
# hint: download.file is really handy when it comes to downloading material from the web
# the dest file is the location on your computer, here it is my working directory
# and url points to the place where you want to get the file from

# we are entering the whole Twitter API info and call the whole object authenticate
authenticate <-  OAuthFactory$new(consumerKey=key,
                 consumerSecret=secret,
                 requestURL='https://api.twitter.com/oauth/request_token',
                 accessURL='https://api.twitter.com/oauth/access_token',
                 authURL='https://api.twitter.com/oauth/authorize')

# this will get you to a Twitter Site - obtain the PIN
# the whole process is meant to provide the signature for your Twitter usage
authenticate$handshake(cainfo="C:/Users/suyas/Downloads/TwitteR/cacert.pem")

# insert the PIN from Twitter
4284444
save(authenticate, file="twitter authentication.Rdata")

registerTwitterOAuth(authenticate)

#alternative authentication method 2

setup_twitter_oauth(key, secret, mytoken, secrettk)

```

```{r}
# Lets start with the Twitter scraping

library("twitteR")
library("httr")

# we need to specify the cainfo to avoid a SSL cert error - this is for Windows machines
# Lets check the latest tweets of Tata
userTimeline("Tata", cainfo="C:/Users/suyas/Downloads/TwitteR/cacert.pem")




# searchTwitter is the main function of the package

?searchTwitter

# arguments: since and until are for time specifications
# lang: for languge specification
# geocode: for location specification

# we are now scraping 1k tweekts for Tata, and we als specify our certificate
Tatatweets = searchTwitter("#coinbase", n=100)

# as you can see, scraping that data is quite time consuming - your machine limits the
# the efficiency and speed of your mining 
# if you are plan to scrape a lot in the future 64bit systems and high RAM is desireable

class(Tatatweets)
length(Tatatweets)
head(Tatatweets)
#install.packages("tm")
library("tm")

Tatalist <- sapply(Tatatweets, function(x) x$getText()) # initiating a function
# in depth info about the apply family and functions in the course "R Level 1"

Tatacorpus <- Corpus(VectorSource(Tatalist)) # use the corpus function
# a corpus is the text body consisting of all the text including the meta info

Tatacorpus<-tm_map(Tatacorpus, function(x) iconv(enc2utf8(x), sub = "byte"))


Tatacorpus <- tm_map(Tatacorpus,tolower)
# putting text to lower case

Tatacorpus <- tm_map(Tatacorpus, removePunctuation) # remove punct.

Tatacorpus <- tm_map(Tatacorpus,
                           function(x)removeWords(x,stopwords())) # remove stopwords (meaningless words)

# there is a link to a stop word list in the link lecture

# Lets see which other transformations tm offers
#?getTransformations

  # to trasform to plain text which wordcloud can use
#Tatacorpus <- tm_map(Tatacorpus, PlainTextDocument)
#install.packages("wordcloud")
library("wordcloud")

#?wordcloud
#install.packages("SnowballC")
#library("SnowballC")
wordcloud(Tatacorpus, min.freq=4, scale=c(5,1),random.color=F, max.word=45,random.order=F)
```
```{r}
# changing to a tdm
Tatatdm <- TermDocumentMatrix(Tatacorpus)

# a DocumentTermMatrix is a very useful tool when it comes to text mining
# it structures the text in a matrix where each term is organized in a column
# each row is a document and the number represents the counts of that term

Tatatdm

# frequent terms
findFreqTerms(Tatatdm, lowfreq=15)

?findFreqTerms

# associations
findAssocs(Tatatdm, 'new', 0.50)

# Lets get a dendrogram to see related terms

# Remove sparse (infrequently used) terms from the term-document matrix
Tata2tdm <-removeSparseTerms(Tatatdm, sparse=0.9)

# Lets scale the data
Tata2tdmscale <- scale(Tata2tdm)

# distance matrix
Tatadist <- dist(Tata2tdmscale, method = "euclidean")

# hierarchical clustering
Tatafit <- hclust(Tatadist)

# Visualize the result
plot(Tatafit)

# to calculate a certain number of groups
cutree(Tatafit, k=6)

# we can even color the 6 groups and plot them
rect.hclust(Tatafit, k=6, border="red")
```